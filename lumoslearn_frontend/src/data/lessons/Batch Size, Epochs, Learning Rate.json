{
  "title": "Batch Size, Epochs, Learning Rate",
  "content": "These three terms are crucial <span style=\"color:#A3F7BF\">hyperparameters</span> that significantly influence the training process and performance of a neural network:<br><br><i>1. <b>Batch Size:</b></i> The number of training examples utilized in one <span style=\"color:#A3F7BF\">iteration</span>. Instead of updating the model's weights after every single training example (which is Stochastic Gradient Descent), or after processing the entire dataset (which is Batch Gradient Descent), we process data in smaller batches. A larger batch size provides a more stable estimate of the gradient but requires more memory and can lead to slower convergence.<br><br><i>2. <b>Epochs:</b></i> One <span style=\"color:#A3F7BF\">epoch</span> means one complete pass through the entire training dataset. During one epoch, the model processes every training example once, performs forward propagation, calculates loss, backpropagates, and updates weights. Training typically involves many epochs until the model converges.<br><br><i>3. <b>Learning Rate:</b></i> A critical hyperparameter that determines the <span style=\"color:#A3F7BF\">step size</span> at each iteration while moving towards a minimum of the loss function. A high learning rate can cause the model to overshoot the minimum, while a very low learning rate can lead to slow convergence or getting stuck in local minima.",
  "quiz": [
    {
      "question": "What does \"Batch Size\" refer to in neural network training?",
      "options": [
        "The total number of training examples",
        "The number of hidden layers",
        "The number of training examples processed in one iteration",
        "The size of the output layer"
      ],
      "answer": 2
    },
    {
      "question": "What is an \"Epoch\" in the context of neural network training?",
      "options": [
        "A single forward pass of one data point",
        "One complete pass through the entire training dataset",
        "The time taken for a single weight update",
        "The number of neurons in a layer"
      ],
      "answer": 1
    },
    {
      "question": "What does the \"Learning Rate\" control during training?",
      "options": [
        "The number of epochs",
        "The step size for weight updates",
        "The batch size",
        "The activation function choice"
      ],
      "answer": 1
    }
  ],
  "title_hi": "बैच का आकार, युग, सीखने की दर",
  "content_hi": "ये तीन शब्द महत्वपूर्ण हैं <स्पैन स्टाइल = \"रंग:#a3f7bf\"> हाइपरपैमीटर </span> जो एक तंत्रिका नेटवर्क के प्रशिक्षण प्रक्रिया और प्रदर्शन को महत्वपूर्ण रूप से प्रभावित करते हैं: <br> <br> <i> 1। <b> बैच का आकार: </b> </i> एक <स्पैन स्टाइल = \"रंग:#a3f7bf\"> iteration </span> में उपयोग किए गए प्रशिक्षण उदाहरणों की संख्या। हर एक प्रशिक्षण उदाहरण (जो स्टोकेस्टिक ग्रेडिएंट डिसेंट है) के बाद मॉडल के वेट को अपडेट करने के बजाय, या पूरे डेटासेट (जो बैच ग्रेडिएंट डिसेंट है) को संसाधित करने के बाद, हम छोटे बैचों में डेटा को संसाधित करते हैं। एक बड़ा बैच आकार ढाल का अधिक स्थिर अनुमान प्रदान करता है, लेकिन अधिक मेमोरी की आवश्यकता होती है और यह धीमी गति से अभिसरण हो सकता है। <br> <br> <i> 2। <b> epochs: </b> </i> एक <span style = \"color:#a3f7bf\"> epoch </span> का मतलब है कि पूरे प्रशिक्षण डेटासेट के माध्यम से एक पूर्ण पास। एक युग के दौरान, मॉडल प्रत्येक प्रशिक्षण उदाहरण को एक बार संसाधित करता है, आगे प्रसार करता है, नुकसान की गणना करता है, बैकप्रोपैगेट्स और वेट अपडेट करता है। प्रशिक्षण में ���मतौर पर कई युग शामिल होते हैं जब तक कि मॉडल परिवर्तित नहीं होता है। <br> <br> <i> 3। <b> सीखने की दर: </b> </i> एक महत्वपूर्ण हाइपरपैमीटर जो <स्पैन स्टाइल = \"रंग:#a3f7bf\"> चरण आकार </span> को निर्धारित करता है, जबकि प्रत्येक पुनरावृत्ति पर न्यूनतम हानि फ़ंक्शन की ओर बढ़ता है। एक उच्च सीखने की दर मॉडल को न्यूनतम की देखरेख करने का कारण बन सकती है, जबकि बहुत कम सीखने की दर धीमी गति से अभिसरण हो सकती है या स्थानीय मिनीमा में फंस सकती है।",
  "quiz_hi": [
    {
      "question": "तंत्रिका नेटवर्क प्रशिक्षण में \"बैच आकार\" क्या संदर्भित करता है?",
      "options": [
        "प्रशिक्षण उदाहरणों की कुल संख्या",
        "छिपी हुई परतों की संख्या",
        "एक पुनरावृत्ति में संसाधित प्रशिक्षण उदाहरणों की संख्या",
        "आउटपुट लेयर का आकार"
      ],
      "answer": 2
    },
    {
      "question": "तंत्रिका नेटवर्क प्रशिक्षण के संदर्भ में एक \"युग\" क्या है?",
      "options": [
        "एक डेटा बिंदु का एक एकल आगे पास",
        "एक पूर्ण प्रशिक्षण डेटासेट के माध्यम से एक पूरा पास",
        "एक एकल वजन अद्यतन के लिए लिया गया समय",
        "एक परत में न्यूरॉन्स की संख्या"
      ],
      "answer": 1
    },
    {
      "question": "प्रशिक्षण के दौरान \"सीखने की दर\" क्या नियंत्रण करती है?",
      "options": [
        "युगों की संख्या",
        "वजन अपडेट के लिए चरण का आकार",
        "बैच का आकार",
        "सक्रियण फ़ंक्शन विकल्प"
      ],
      "answer": 1
    }
  ]
}