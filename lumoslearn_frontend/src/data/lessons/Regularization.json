{
  "title": "Regularization",
  "content": "<b>Regularization</b> techniques are crucial in Deep Learning to prevent <span style=\"color:#A3F7BF\">overfitting</span>. Overfitting occurs when a model learns the training data too well, including noise and specific patterns, leading to poor performance on new, unseen data.<br><br>Regularization methods work by adding a <span style=\"color:#A3F7BF\">penalty term to the loss function</span> during training. This penalty discourages the model from assigning excessively large weights to features, thereby reducing the model's complexity and making it more robust.<br><br>Common types of regularization include:<br><i>1. <b>L1 Regularization (Lasso):</b></i> Adds the absolute value of the weights to the loss function. It can lead to <span style=\"color:#A3F7BF\">sparse models</span>, effectively setting some weights to zero and performing feature selection.<br><i>2. <b>L2 Regularization (Ridge):</b></i> Adds the squared magnitude of the weights to the loss function. It encourages smaller weights, distributing the importance across all features.",
  "quiz": [
    {
      "question": "What problem does regularization primarily aim to prevent?",
      "options": [
        "Underfitting",
        "Overfitting",
        "Slow training",
        "Vanishing gradients"
      ],
      "answer": 1
    },
    {
      "question": "How does regularization typically work?",
      "options": [
        "By increasing the learning rate",
        "By adding a penalty term to the loss function",
        "By reducing the number of training epochs",
        "By using a different activation function"
      ],
      "answer": 1
    },
    {
      "question": "Which type of regularization can lead to sparse models by setting some weights to zero?",
      "options": [
        "L2 Regularization",
        "Dropout",
        "L1 Regularization",
        "Batch Normalization"
      ],
      "answer": 2
    }
  ],
  "title_hi": "नियमितीकरण",
  "content_hi": "<b> नियमितीकरण </b> तकनीकें गहरी सीखने में महत्वपूर्ण हैं <स्पैन स्टाइल = \"रंग:#a3f7bf\"> overfitting </span>। ओवरफिटिंग तब होता है जब कोई मॉडल प्रशिक्षण डेटा को अच्छी तरह से सीखता है, जिसमें शोर और विशिष्ट पैटर्न शामिल हैं, जिससे नए, अनदेखी डेटा पर खराब प्रदर्शन होता है। <br> <br> नियमितीकरण के तरीके एक <स्पैन स्टाइल = \"रंग:#A3F7BF\"> प्रशिक्षण के दौरान नुकसान समारोह </स्पैन> के लिए दंड शब्द जोड़कर काम करते हैं। यह जुर्माना मॉडल को अत्यधिक बड़े वज़न को विशेषताओं के लिए असाइन करने से हतोत्साहित करता है, जिससे मॉडल की जटिलता को कम किया जाता है और इसे और अधिक मजबूत बना दिया जाता है। <br> <br> सामान्य प्रकार के नियमितीकरण में शामिल हैं: <br> <i> 1। <b> l1 नियमितीकरण (LASSO): </b> </i> हानि फ़ंक्शन में वजन का निरपेक्ष मान जोड़ता है। यह <स्पैन स्टाइल = \"रंग:#a3f7bf\"> स्पार्स मॉडल </span>, प्रभावी रूप से शून्य पर कुछ वजन सेट करने और सुविधा चयन करने के लिए नेतृत्व कर सकता है। <br> <i> 2। <b> l2 नियमितीकरण (रिज): </b> </i> वजन के वर्ग परिमाण को नुकसान समारोह में जोड़ता है। यह छोटे वजन को प्रोत्साहित करता है, सभी विशेषताओं में महत्व को वितरित करता है।",
  "quiz_hi": [
    {
      "question": "नियमितीकरण मुख्य रूप से क्या समस्या है?",
      "options": [
        "कमज़ोर",
        "अतिप्रवाह",
        "धीमी प्रशिक्षण",
        "गायब हो जाना"
      ],
      "answer": 1
    },
    {
      "question": "नियमितीकरण आम तौर पर कैसे काम करता है?",
      "options": [
        "सीखने की दर बढ़ाकर",
        "नुकसान समारोह में एक दंड शब्द जोड़कर",
        "प्रशिक्षण युगों की संख्या को कम करके",
        "एक अलग सक्रियण फ़ंक्शन का उपयोग करके"
      ],
      "answer": 1
    },
    {
      "question": "किस प्रकार के नियमितीकरण से कुछ वज़न शून्य पर सेट करके विरल मॉडल हो सकते हैं?",
      "options": [
        "एल 2 नियमितीकरण",
        "ड्रॉप आउट",
        "एल 1 नियमितीकरण",
        "बैच सामान्यीकरण"
      ],
      "answer": 2
    }
  ]
}