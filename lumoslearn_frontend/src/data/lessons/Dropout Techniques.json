{
  "title": "Dropout Techniques",
  "content": "<b>Dropout</b> is a powerful and widely used <span style=\"color:#A3F7BF\">regularization technique</span> specifically designed for neural networks. It addresses overfitting by randomly \"dropping out\" (setting to zero) a proportion of neurons during each training iteration.<br><br>During training, for each update of the network, individual neurons are temporarily removed from the network with a certain probability (e.g., 0.5). This means that their connections to other neurons are also removed. This process is done randomly and independently for each neuron.<br><br>The benefits of dropout include:<br><i>1. <b>Prevents Co-adaptation:</b></i> It forces neurons to learn more robust features that are useful in conjunction with different random subsets of other neurons, rather than relying too heavily on specific connections.<br><i>2. <b>Ensemble Effect:</b></i> Dropout can be seen as training an ensemble of many different neural networks, where each network is a sub-network of the original. At test time, all neurons are active, but their outputs are scaled by the dropout probability.",
  "quiz": [
    {
      "question": "What does Dropout randomly do during training?",
      "options": [
        "Adds new neurons",
        "Drops out (sets to zero) a proportion of neurons",
        "Changes the learning rate",
        "Initializes weights"
      ],
      "answer": 1
    },
    {
      "question": "What is a key benefit of using Dropout?",
      "options": [
        "It speeds up forward propagation",
        "It prevents co-adaptation of neurons",
        "It increases the model's complexity",
        "It reduces the need for activation functions"
      ],
      "answer": 1
    },
    {
      "question": "When is Dropout typically applied?",
      "options": [
        "Only during inference",
        "Only during data preprocessing",
        "During each training iteration",
        "After the model has fully converged"
      ],
      "answer": 2
    }
  ],
  "title_hi": "ड्रॉपआउट तकनीक",
  "content_hi": "<b> ड्रॉपआउट </b> एक शक्तिशाली और व्यापक रूप से उपयोग किया जाता है <स्पैन स्टाइल = \"रंग:#a3f7bf\"> नियमितीकरण तकनीक </span> विशेष रूप से तंत्रिका नेटवर्क के लिए डिज़ाइन किया गया है। यह प्रत्येक प्रशिक्षण पुनरावृत्ति के दौरान न्यूरॉन्स का अनुपात बेतरतीब ढंग से \"छोड़ने\" (शून्य पर सेटिंग) द्वारा ओवरफिटिंग को संबोधित करता है। <br> <br> <br> प्रशिक्षण के दौरान, नेटवर्क के प्रत्येक अपडेट के लिए, व्यक्तिगत न्यूरॉ��्स को अस्थायी रूप से नेटवर्क से एक निश्चित संभावना (जैसे, 0.5) के साथ अस्थायी रूप से हटा दिया जाता है। इसका मतलब यह है कि अन्य न्यूरॉन्स के लिए उनके कनेक्शन को भी हटा दिया जाता है। यह प्रक्रिया प्रत्येक न्यूरॉन के लिए बेतरतीब ढंग से और स्वतंत्र रूप से की जाती है। <br> <br> ड्रॉपआउट के लाभों में शामिल हैं: <br> <i> 1। <b> सह-अनुकूलन को रोक��ा है: </b> </i> यह न्यूरॉन्स को अधिक मजबूत सुविधाओं को जानने के लिए मजबूर करता है जो अन्य न्यूरॉन्स के विभिन्न यादृच्छिक सबसेट के साथ संयोजन में उपयोगी हैं, बजाय विशिष्ट कनेक्शनों पर बहुत अधिक निर्भर करने के। <br> <i> 2। <b> पहनावा प्रभाव: </b> </i> ड्रॉपआउट को कई अलग-अलग तंत्रिका नेटवर्क के एक पहनावा के प्रशिक्षण के रूप में देखा जा सकता है, जहां प्रत्येक नेटवर्क मूल का एक उप-नेटवर्क है। परीक्षण के समय, सभी न्यूरॉन्स सक्रिय होते हैं, लेकिन उनके आउटपुट को ड्रॉपआउट संभावना द्वारा बढ़ाया जाता है।",
  "quiz_hi": [
    {
      "question": "प्रशिक्षण के दौरान ड्रॉपआउट बेतरतीब ढंग से क्या करता है?",
      "options": [
        "नए न्यूरॉन्स जोड़ता है",
        "न्यूरॉन्स का अनुपात (शून्य पर सेट) को छोड़ देता है",
        "सीखने की दर बदल देता है",
        "वेट इनिशियलाइज़ करता है"
      ],
      "answer": 1
    },
    {
      "question": "ड्रॉपआउट का उपयोग करने का एक महत्वपूर्ण लाभ क्या है?",
      "options": [
        "यह आगे के प्रसार को गति देता है",
        "यह न्यूरॉन्स के सह-अनुकूलन को रोकता है",
        "यह मॉडल की जटिलता को बढ़ाता है",
        "यह सक्रियण कार्यों की आवश्यकता को कम करता है"
      ],
      "answer": 1
    },
    {
      "question": "आमतौर पर ड्रॉपआउट कब लागू होता है?",
      "options": [
        "केवल अनुमान के दौरान",
        "केवल डेटा प्रीप्रोसेसिंग के दौरान",
        "प्रत्येक प्रशिक्षण पुनरावृत्ति के दौरान",
        "मॉडल के बाद पूरी तरह से अभिसरण हो गया है"
      ],
      "answer": 2
    }
  ]
}