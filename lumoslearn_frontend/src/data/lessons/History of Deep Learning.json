{
  "title": "History of Deep Learning",
  "content": "The journey of Deep Learning began with early concepts like the <span style=\"color:#A3F7BF\">Perceptron in the 1950s and 60s</span>. However, limitations such as the inability of single-layer perceptrons to solve non-linear problems (like XOR) led to an 'AI winter' in the 1980s.<br><br>The resurgence began in the late 1980s with the development of <span style=\"color:#A3F7BF\">backpropagation</span>, which allowed training of multi-layer neural networks. Despite this, computational power and data availability remained significant bottlenecks.<br><br>The true explosion of Deep Learning occurred in the <span style=\"color:#A3F7BF\">2000s and 2010s</span>, driven by:<br><i>1. Vastly increased computational power (especially GPUs).<br>2. Availability of massive datasets.<br>3. Development of new algorithms and architectures (e.g., ReLU, CNNs, RNNs).</i><br><br>Landmark achievements like AlexNet's success in image recognition in 2012 cemented Deep Learning's position as a dominant force in AI.",
  "quiz": [
    {
      "question": "Which early model marked a significant step in the history of Deep Learning?",
      "options": [
        "Support Vector Machine",
        "Decision Tree",
        "Perceptron",
        "K-Means Clustering"
      ],
      "answer": 2
    },
    {
      "question": "What algorithm was crucial for training multi-layer neural networks and contributed to the resurgence of Deep Learning?",
      "options": [
        "Linear Regression",
        "Backpropagation",
        "Gradient Boosting",
        "Principal Component Analysis"
      ],
      "answer": 1
    },
    {
      "question": "Which factor was NOT a primary driver of the recent explosion in Deep Learning?",
      "options": [
        "Increased computational power",
        "Availability of massive datasets",
        "Decreased interest in AI research",
        "Development of new algorithms"
      ],
      "answer": 2
    }
  ],
  "title_hi": "गहरी शिक्षा का इतिहास",
  "content_hi": "गहरी सीखने की यात्रा प्रारंभिक अवधारणाओं के साथ शुरू हुई जैसे <स्पैन स्टाइल = \"रंग:#a3f7bf\"> 1950 और 60 के दशक में </span> में perceptron। हालांकि, गैर-रेखीय समस्याओं (जैसे कि XOR) को हल करने के लिए एकल-परत पर्सप्रेट्रॉन की अक्षमता जैसी सीमाएं 1980 के दशक में 'एआई विंटर' का नेतृत्व करती हैं। <br> <br> <br> 1980 के दशक के अंत में पुनरुत्थान की शुरुआत <स्पैन स्टाइल = \"रंग:#A3F7BF\"> बैकप्रोपैगेशन </स्पैन> के विकास के साथ हुई। इसके बावजूद, कम्प्यूटेशनल पावर और डेटा उपलब्धता महत्वपूर्ण अड़चनें बनी रही। <br> <br> <br> गहरी सीखने का सच्चा विस्फोट <स्पैन स्टाइल = \"रंग:#A3F7BF\"> 2000S और 2010s </स्पैन> में हुआ, द्वारा संचालित: <br> <i> 1। भारी रूप से बढ़ी हुई कम्प्यूटेशनल शक्ति (विशेष रूप से GPU)। <br> 2। बड़े पैमाने पर डेटासेट की उपलब्धता। <br> 3। नए एल्गोरिदम और आर्किटेक्चर (जैसे, रिलू, सीएनएनएस, आरएनएनएस) का विकास।",
  "quiz_hi": [
    {
      "question": "किस शुरुआती मॉडल ने गहन सीखने के इतिहास में एक महत्वपूर्ण कदम चिह्नित किया?",
      "options": [
        "सहमति वेक्टर मशीन",
        "निर्णय वृक्ष",
        "पाइसपट्रॉन",
        "के-साधन क्लस्टरिंग"
      ],
      "answer": 2
    },
    {
      "question": "बहु-परत तंत्रिका नेटवर्क को प्रशिक्षित करने के लिए क्या एल्गोरिथ्म महत्वपूर्ण था और गहरी सीखने के पुनरुत्थान में योगदान दिया?",
      "options": [
        "रेखीय प्रतिगमन",
        "बैकप्रोपैगेशन",
        "ढाल को बढ़ावा देना",
        "प्रधान घटक विश्लेषण"
      ],
      "answer": 1
    },
    {
      "question": "डीप लर्निंग में हाल ही में विस्फोट का कौन सा कारक प्राथमिक चालक नहीं था?",
      "options": [
        "कम्प्यूटेशनल शक्ति में वृद्धि हुई है",
        "बड़े पैमाने पर डेटासेट की उपलब्धता",
        "एआई अनुसंधान में रुचि कम हो गई",
        "नए एल्गोरिदम का विकास"
      ],
      "answer": 2
    }
  ]
}